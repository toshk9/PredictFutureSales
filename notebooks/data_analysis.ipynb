{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import statsmodels.api as sm\n",
    "\n",
    "from typing import List\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"../\") \n",
    "\n",
    "from src.data.etl_layer import ETL\n",
    "from src.data.dqc_layer import DQC\n",
    "from src.data.eda_layer import EDA\n",
    "\n",
    "from src.modelling.feature_extraction import Feature_Extraction as FE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "84 rows and 2 columns has been read from item_categories.csv\n",
      "\n",
      "22170 rows and 3 columns has been read from items.csv\n",
      "\n",
      "2935849 rows and 6 columns has been read from sales_train.csv\n",
      "\n",
      "60 rows and 2 columns has been read from shops.csv\n",
      "\n",
      "214200 rows and 3 columns has been read from test.csv\n"
     ]
    }
   ],
   "source": [
    "# creating instances of the ETL class for each dataset and extracting data\n",
    "\n",
    "item_categories_etl: ETL = ETL(\"../data/raw/item_categories.csv\")\n",
    "items_etl: ETL = ETL(\"../data/raw/items.csv\")\n",
    "sales_etl: ETL = ETL(\"../data/raw/sales_train.csv\")\n",
    "shops_etl: ETL = ETL(\"../data/raw/shops.csv\")\n",
    "test_etl: ETL = ETL(\"../data/raw/test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# receiving extracted data in the form of dataframes\n",
    "\n",
    "item_categories_df: pd.DataFrame = item_categories_etl.get_data()\n",
    "items_df: pd.DataFrame = items_etl.get_data()\n",
    "sales_df: pd.DataFrame = sales_etl.get_data()\n",
    "shops_df: pd.DataFrame = shops_etl.get_data()\n",
    "test_df: pd.DataFrame = test_etl.get_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DQC\n",
    "* overview of the data (types of data, descriptive statistics and data examples) for each dataset and a more detailed analysis of the data of the 'sales_train.csv' dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating instances of the DQC class for each DataFrame\n",
    "\n",
    "item_categories_dqc: DQC = DQC(item_categories_df, item_categories_etl.df_title)\n",
    "items_dqc: DQC = DQC(items_df, items_etl.df_title)\n",
    "sales_dqc: DQC = DQC(sales_df, sales_etl.df_title)\n",
    "shops_dqc: DQC = DQC(shops_df, shops_etl.df_title)\n",
    "test_dqc: DQC = DQC(test_df, test_etl.df_title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_categories_dqc.data_review()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "items_dqc.data_review()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shops_dqc.data_review()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dqc.data_review()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_dqc.data_review()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# outliers check (for item_price and item_cnt_day columns in the sales DataFrame)\n",
    "\n",
    "columns_outliers: dict = sales_dqc.outliers_check([\"item_price\", \"item_cnt_day\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualization of item_price and item_cnt_day columns of the sales DataFrame "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting IQR boundaries for item_price values \n",
    "item_price_interval_border_1: np.float64 = columns_outliers[\"iqr_interval\"][\"item_price\"][0]\n",
    "item_price_interval_border_2: np.float64 = columns_outliers[\"iqr_interval\"][\"item_price\"][1]\n",
    "\n",
    "# getting item_price values excluding outliers\n",
    "item_price_wo_outliers: pd.Series = sales_df.loc[(sales_df[\"item_price\"] >= item_price_interval_border_1) & (sales_df[\"item_price\"] <= item_price_interval_border_2)][\"item_price\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting IQR boundaries for item_cnt_day values \n",
    "item_cnt_day_interval_border_1: np.float64 = columns_outliers[\"iqr_interval\"][\"item_cnt_day\"][0]\n",
    "item_cnt_day_interval_border_2: np.float64 = columns_outliers[\"iqr_interval\"][\"item_cnt_day\"][1]\n",
    "\n",
    "# getting item_cnt_day values excluding outliers\n",
    "item_cnt_day_wo_outliers: pd.Series = sales_df.loc[(sales_df[\"item_cnt_day\"] >= item_cnt_day_interval_border_1) & (sales_df[\"item_cnt_day\"] <= item_cnt_day_interval_border_2)][\"item_cnt_day\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization\n",
    "fig, ax = plt.subplots(2, 2, figsize=(8, 8))\n",
    "plt.subplots_adjust(hspace=0.4, wspace=0.3)\n",
    "\n",
    "ax[0][0].hist(sales_df[\"item_price\"], bins=32, color=\"lightcoral\")\n",
    "ax[0][1].hist(item_price_wo_outliers, bins=32, color=\"darkcyan\")\n",
    "ax[0][0].axvline(sales_df[\"item_price\"].mean(), color=\"yellow\")\n",
    "ax[0][1].axvline(sales_df[\"item_price\"].mean(), color=\"yellow\")\n",
    "\n",
    "ax[0][0].text(sales_df[\"item_price\"].mean() - 12000, 1000, s=f\"{sales_df['item_price'].mean() : .2f}\", rotation=90, color=\"orange\")\n",
    "ax[0][1].text(sales_df[\"item_price\"].mean() - 100, 200000, s=f\"{sales_df['item_price'].mean() : .2f}\", rotation=90, color=\"orange\")\n",
    "\n",
    "ax[0][0].legend([\"mean\", \"frequency\"])\n",
    "ax[0][1].legend([\"mean\", \"frequency\"])\n",
    "\n",
    "ax[0][0].set_title(\"item_price histogram with outliers\")\n",
    "ax[0][1].set_title(\"item_price histogram without outliers\")\n",
    "\n",
    "ax[0][0].set_xlabel(\"item price\")\n",
    "ax[0][1].set_xlabel(\"item price\")\n",
    "#\n",
    "ax[1][0].hist(sales_df[\"item_cnt_day\"], bins=32, color=\"lightcoral\")\n",
    "ax[1][1].hist(item_cnt_day_wo_outliers, bins=32, color=\"darkcyan\")\n",
    "ax[1][0].axvline(item_cnt_day_wo_outliers.mean(), color=\"yellow\")\n",
    "ax[1][1].axvline(item_cnt_day_wo_outliers.mean(), color=\"yellow\")\n",
    "\n",
    "ax[1][0].text(item_cnt_day_wo_outliers.mean() - 100, 1000, s=f\"{sales_df['item_cnt_day'].mean() : .2f}\", rotation=90, color=\"orange\")\n",
    "ax[1][1].text(item_cnt_day_wo_outliers.mean() - 0.05, 1500000, s=f\"{item_cnt_day_wo_outliers.mean().mean() : .2f}\", rotation=90, color=\"orange\")\n",
    "\n",
    "ax[1][0].legend([\"mean\", \"frequency\"])\n",
    "ax[1][1].legend([\"mean\", \"frequency\"])\n",
    "\n",
    "ax[1][0].set_title(\"item_cnt_day histogram with outliers\")\n",
    "ax[1][1].set_title(\"item_cnt_day histogram without outliers\")\n",
    "\n",
    "ax[1][0].set_xlabel(\"item amount per day\")\n",
    "ax[1][1].set_xlabel(\"item amount per day\")\n",
    "\n",
    "ax[0][0].set_yscale(\"symlog\")\n",
    "ax[1][0].set_yscale(\"symlog\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ids availability check\n",
    "missing_shop_ids_idx: pd.Index = sales_df[~sales_df[\"shop_id\"].isin(shops_df[\"shop_id\"])].index\n",
    "missing_item_ids_idx: pd.Index = sales_df[~sales_df[\"item_id\"].isin(items_df[\"item_id\"])].index\n",
    "missing_item_categories_idx: pd.Index = items_df[~items_df[\"item_category_id\"].isin(item_categories_df[\"item_category_id\"])].index\n",
    "\n",
    "print(f\"Row indexes of missing sales_train item ids in items_df: {list(missing_item_ids_idx)}\")\n",
    "print(f\"Row indexes of missing sales_train shop ids in shops_df: {list(missing_shop_ids_idx)}\")\n",
    "print(f\"Row indexes of missing items_df item categories id in item_categories_df: {list(missing_item_categories_idx)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NA values check for sales_train DF \n",
    "_ = sales_dqc.na_values_check()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data consistency and data uniqueness check for sales_train DF \n",
    "for column in sales_df.columns:\n",
    "    print(f\"\\nConsistency column: {column}\")\n",
    "    _ = sales_dqc.consistency_uniqueness_check([column])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data types check for sales_train DF \n",
    "_ = sales_dqc.types_check()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ETL\n",
    "* Processing the sales_train dataframe data and creating a new montnly_sales dataframe based on it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Processing the sales_train dataframe data \n",
    "sales_df_processed: pd.DataFrame = sales_etl.transform([\"item_price\", \"item_cnt_day\"], [\"item_cnt_day\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop not available ids in the processed sales_train DF\n",
    "sales_df_processed.drop(index=missing_item_ids_idx.union(missing_shop_ids_idx), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving the processed sales dataframe in the csv file\n",
    "sales_etl.load_data_csv(\"processed_sales_train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving the processed sales dataframe in the sqlite db\n",
    "sales_etl.load_data_sqlite(\"processed_sales_train\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating a monthly_sales dataframe based on the main sales_train\n",
    "* It will include the monthly sales for each product for each store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adding an Year-month column \n",
    "sales_df_processed[\"month\"]: pd.DataFrame = sales_df_processed[\"date\"].dt.to_period(\"M\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grouping data to calculate monthly amount for a specific item in a specific store\n",
    "monthly_sales: pd.DataFrame = FE(sales_df_processed).create_monthly_df()\n",
    "# monthly_sales[\"month\"] = monthly_sales[\"month\"].dt.strftime(\"%Y-%m\") # converting datetime type into str \n",
    "                                                                    # for data visualization (can be ignored)\n",
    "# monthly_sales[\"month\"] = monthly_sales[\"month\"].astype(\"int64\") # converting datetime type into str \n",
    "\n",
    "\n",
    "print(monthly_sales.shape)\n",
    "monthly_sales.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating instances of the DQC class for monthly_sales DF\n",
    "monthly_sales_dqc: DQC = DQC(monthly_sales)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "monthly_sales_dqc.data_review()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating instances of the DQC class for monthly_sales DF\n",
    "monthly_sales_etl: ETL = ETL(df=monthly_sales)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Processing monthly_sales data\n",
    "monthly_sales_processed: pd.DataFrame = monthly_sales_etl.transform([\"item_cnt_month\"], [\"item_cnt_month\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EDA\n",
    "* Exploratory data analysis for the original sales dataframe, for time series for all unique store-item pairs, and for time series for cumulative monthly and daily sales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating instances of the EDA class for sales DF\n",
    "sales_eda: EDA = EDA(sales_df_processed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking for correlation of sales dataframe features using the listed methods\n",
    "sales_eda.features_corr_check(columns=[\"date_block_num\", \"shop_id\", \"item_id\", \"item_price\", \"item_cnt_day\"], methods=['pearson', 'spearman', 'kendall'], numeric_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking normal distribution for sales dataframe item_price, item_cnt_day columns\n",
    "sales_eda.normal_distr_check([\"item_cnt_day\", \"item_price\"], bins=16, edgecolor=\"coral\", color=\"lightblue\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a dataframe with unique store-item pairs \n",
    "# for subsequent time series analysis for these pairs\n",
    "shop_item_gr: pd.DataFrame = pd.DataFrame(sales_df_processed.groupby([\"shop_id\", \"item_id\"])[\"item_cnt_day\"].sum())\n",
    "shop_item_df = shop_item_gr.reset_index() # converting indexes into columns\n",
    "shop_item_df = shop_item_df[[\"shop_id\", \"item_id\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ts stationarity check for unique shop-item pairs \n",
    "import warnings\n",
    "\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning)\n",
    "warnings.filterwarnings(\"ignore\", message=\"The test statistic is outside of the range of p-values\")\n",
    "\n",
    "nonstationary_shop_item: List[dict] = []\n",
    "for r in shop_item_df.iterrows():\n",
    "    shop_id: int = r[1][\"shop_id\"]\n",
    "    item_id: int = r[1][\"item_id\"]\n",
    "\n",
    "    shop_item_ts: pd.DataFrame = monthly_sales.loc[(monthly_sales[\"shop_id\"] == shop_id) & (monthly_sales[\"item_id\"] == item_id)]\n",
    "    if shop_item_ts.shape[0] >= 20:\n",
    "        shop_item_stationarity: tuple = EDA(shop_item_ts).ts_stationarity_check(\"item_cnt_month\")\n",
    "        if shop_item_stationarity[0] != \"stationary\": \n",
    "            nonstationary_shop_item.append({\"shop_id\": shop_id, \"item_id\": item_id, \"stationarity\" : shop_item_stationarity[0], \"tests_stats\": {\"adf_stats\" : shop_item_stationarity[1], \"kpss_stats\" : shop_item_stationarity[2]}})\n",
    "            print(f\"For {shop_id} shop_id and {item_id} item_id time series is {shop_item_stationarity[0]}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# non-stationarity processing for unique shop-item pairs \n",
    "for shop_item in nonstationary_shop_item:\n",
    "    shop_id: int = shop_item[\"shop_id\"]\n",
    "    item_id: int = shop_item[\"item_id\"]\n",
    "\n",
    "    shop_item_ts: pd.DataFrame = monthly_sales.loc[(monthly_sales[\"shop_id\"] == shop_id) & (monthly_sales[\"item_id\"] == item_id)]\n",
    "    shop_item_ts_etl: ETL = ETL(df=shop_item_ts)\n",
    "    proc_shop_item_ts: pd.DataFrame = shop_item_ts_etl.ts_nonstatinarity_processing(\"item_cnt_month\")\n",
    "    monthly_sales.loc[(monthly_sales[\"shop_id\"] == shop_id) & (monthly_sales[\"item_id\"] == item_id), \"item_cnt_month\"] = proc_shop_item_ts\n",
    "    print(f\"TS for {shop_id} shop and {item_id} item processed.\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# autocorrelation check for unique shop-item pairs \n",
    "ac_shop_item: List[dict] = []\n",
    "for r in shop_item_df.iterrows():\n",
    "    shop_id: int = r[1][\"shop_id\"]\n",
    "    item_id: int = r[1][\"item_id\"]\n",
    "\n",
    "    lags_num: int = 3\n",
    "\n",
    "    shop_item_ts: pd.DataFrame = monthly_sales.loc[(monthly_sales[\"shop_id\"] == shop_id) & (monthly_sales[\"item_id\"] == item_id)]\n",
    "    if shop_item_ts.shape[0] >= lags_num:\n",
    "        shop_item_ac_lags = EDA(shop_item_ts).ts_autocorr_check(\"item_cnt_month\", lags_num)\n",
    "        if len(shop_item_ac_lags) >= 1: \n",
    "            ac_shop_item.append({\"shop_id\": shop_id, \"item_id\": item_id, \"lags\": shop_item_ac_lags})\n",
    "            print(f\"For {shop_id} shop_id and {item_id} item_id autocorrelation for {shop_item_ac_lags} lags detected.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ACF-PACF for shop-item sample\n",
    "shop_item_sample = ac_shop_item[3]\n",
    "\n",
    "shop_id: int = shop_item_sample[\"shop_id\"]\n",
    "item_id: int = shop_item_sample[\"item_id\"]\n",
    "x = monthly_sales.loc[(monthly_sales[\"shop_id\"] == shop_id) & (monthly_sales[\"item_id\"] == item_id), \"item_cnt_month\"]\n",
    "\n",
    "sm.graphics.tsa.plot_acf(x.values.squeeze(), lags=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# heteroskedasticity check for monthly_sales DF\n",
    "EDA(monthly_sales).heterosked_check([\"shop_id\", \"item_id\"], \"item_cnt_month\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# monthly data\n",
    "monthly_sales_sum = monthly_sales.groupby([\"month\"])[\"item_cnt_month\"].sum()\n",
    "monthly_sales_sum = pd.DataFrame(monthly_sales_sum).reset_index()\n",
    "monthly_sales_sum.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(monthly_sales_sum[\"month\"].dt.strftime(\"%Y-%m\"), monthly_sales_sum.item_cnt_month)\n",
    "plt.title(\"Monthly sales sum\", fontsize=14)\n",
    "plt.xticks(monthly_sales_sum[\"month\"].dt.strftime(\"%Y-%m\")[::2], rotation=45)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# daily data\n",
    "sales_df['date'] = pd.to_datetime(sales_df[\"date\"], dayfirst=True)\n",
    "daily_sales_sum = sales_df.groupby([\"date\"])[\"item_cnt_day\"].sum()\n",
    "daily_sales_sum = pd.DataFrame(daily_sales_sum).reset_index()\n",
    "daily_sales_sum.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(daily_sales_sum[\"date\"].dt.strftime(\"%Y-%m-%d\"), daily_sales_sum.item_cnt_day)\n",
    "plt.title(\"Daily sales sum\", fontsize=14)\n",
    "plt.xticks(daily_sales_sum[\"date\"].dt.strftime(\"%Y-%m-%d\")[::50], rotation=45)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ts monthly sales stationarity check and processing\n",
    "stationary_monthly_sales_sum: ETL = ETL(df=monthly_sales_sum).ts_nonstatinarity_processing(\"item_cnt_month\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "monthly_sales_sum[\"month\"] = monthly_sales_sum[\"month\"].astype(\"int64\")\n",
    "# creating instances of the EDA class for monthly_sales_sum DF\n",
    "monthly_sales_sum_eda: EDA = EDA(stationary_monthly_sales_sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ts monthly sales autocorrelation check \n",
    "monthly_sales_sum_eda.ts_autocorr_check(\"item_cnt_month\", 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# monthly sales heteroskedasticity check\n",
    "monthly_sales_sum_eda.heterosked_check([\"month\"], \"item_cnt_month\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ts daily sales stationarity check and processing\n",
    "stationary_daily_sales_sum: ETL = ETL(df=daily_sales_sum).ts_nonstatinarity_processing(\"item_cnt_day\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "daily_sales_sum[\"date\"] = daily_sales_sum[\"date\"].astype(\"int64\")\n",
    "# creating instances of the EDA class for daily_sales_sum DF\n",
    "daily_sales_sum_eda: EDA = EDA(stationary_daily_sales_sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ts daily sales autocorrelation check \n",
    "daily_sales_sum_eda.ts_autocorr_check(\"item_cnt_day\", 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# daily sales heteroskedasticity check\n",
    "daily_sales_sum_eda.heterosked_check([\"date\"], \"item_cnt_day\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
