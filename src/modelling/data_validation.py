import tensorflow_data_validation as tfdv

from typing import Union
from tensorflow_metadata.proto.v0 import schema_pb2
from tensorflow_metadata.proto.v0 import statistics_pb2

import pandas as pd

import os


class Data_Validation:
    """
    A class for validating and analyzing data using TensorFlow Data Validation (TFDV).

    Args:
        stats (statistics_pb2.DatasetFeatureStatisticsList, optional): Dataset statistics generated by TFDV.
        schema (schema_pb2.Schema, optional): Data schema generated by TFDV.

    Attributes:
        stats (statistics_pb2.DatasetFeatureStatisticsList): Dataset statistics generated by TFDV.
        schema (schema_pb2.Schema): Data schema generated by TFDV.

    Methods:
        get_stats(): Returns the dataset statistics.
        get_schema(): Returns the data schema and displays it.
        create_stats(ds: Union[pd.DataFrame, str]) -> statistics_pb2.DatasetFeatureStatisticsList:
            Generates dataset statistics from a DataFrame or a file.
        create_schema() -> schema_pb2.Schema: Infers and creates the data schema.
        save_schema(schema_title: str): Saves the data schema to a file.
        save_stats(stats_title: str): Saves the dataset statistics to a file.
        load_schema(schema_path: str) -> schema_pb2.Schema: Loads the data schema from a file.
        load_stats(stats_path: str) -> statistics_pb2.DatasetFeatureStatisticsList: Loads the dataset statistics from a file.
        validate_data(new_stats: statistics_pb2.DatasetFeatureStatisticsList, drift_feature_threshold_dict: dict=None, skew_feature_threshold_dict: dict=None) -> None:
            Validates the new dataset statistics against the existing data statistics, displaying anomalies and visualizations.
    """
    def __init__(self, stats: statistics_pb2.DatasetFeatureStatisticsList=None, schema: schema_pb2.Schema=None) -> None:
        """
        Initializes a Data_Validation object.

        Args:
            stats (statistics_pb2.DatasetFeatureStatisticsList, optional): Dataset statistics generated by TFDV.
            schema (schema_pb2.Schema, optional): Data schema generated by TFDV.
        """
        self.stats: statistics_pb2.DatasetFeatureStatisticsList = stats
        self.schema: schema_pb2.Schema = schema
            
    def get_stats(self) -> statistics_pb2.DatasetFeatureStatisticsList:
        """
        Returns the dataset statistics.

        Raises:
            ValueError: If there are no statistics, use 'create_stats()' to create.
        
        Returns:
            statistics_pb2.DatasetFeatureStatisticsList: Dataset statistics generated by TFDV.
        """
        if self.stats == None:
            raise ValueError("There are no statistics, use 'create_stats()' to create.")
        else:
            return self.stats
    
    def get_schema(self) -> schema_pb2.Schema:
        """
        Returns the data schema and displays it.

        If the schema is not yet created, it creates the schema before returning.

        Returns:
            schema_pb2.Schema: Data schema generated by TFDV.
        """
        if self.schema == None:
            self.create_schema()
        tfdv.display_schema(self.schema)
        return self.schema
    
    def create_stats(self, ds: Union[pd.DataFrame, str]) -> statistics_pb2.DatasetFeatureStatisticsList:
        """
        Generates dataset statistics from a DataFrame or a file.

        Args:
            ds (Union[pd.DataFrame, str]): Dataset as a DataFrame or path to a file.

        Returns:
            statistics_pb2.DatasetFeatureStatisticsList: Dataset statistics generated by TFDV.
        
        Raises:
            ValueError: If the 'ds' argument has an unsupported data type or format.
        """
        if type(ds) is str:
            file_path: str = ds
            file_extension: str = os.path.splitext(file_path)[1]

            if file_extension == '.csv':
                self.stats: statistics_pb2.DatasetFeatureStatisticsList = tfdv.generate_statistics_from_csv(file_path)
            elif file_extension == '.tfrecord':
                self.stats: statistics_pb2.DatasetFeatureStatisticsList = tfdv.generate_statistics_from_tfrecord(file_path)
            else:
                raise ValueError("Wrong data format.")
        elif type(ds) is pd.DataFrame:
            self.stats: statistics_pb2.DatasetFeatureStatisticsList = tfdv.generate_statistics_from_dataframe(ds)
        else:
            raise ValueError("Wrong data type in 'ds' argument.")
        
        print("The Data Stats has been successfully created")
        return self.stats

    def create_schema(self) -> schema_pb2.Schema:
        """
        Infers and creates the data schema.

        Returns:
            schema_pb2.Schema: Data schema generated by TFDV.
        
        Raises:
            ValueError: If there are no statistics, use 'create_stats()' to create.
        """
        print("There is no schema.")
        print("Trying to create a schema...")
        if self.stats != None:
            self.schema: schema_pb2.Schema = tfdv.infer_schema(statistics=self.stats)
            print("The schema has been successfully created")
            tfdv.display_schema(self.schema)
        else:
            raise ValueError("There are no statistics, use 'create_stats()' to create.")
        return self.schema

    def save_schema(self, schema_title: str) -> None:
        """
        Saves the data schema to a file.

        Args:
            schema_title (str): Title for the schema file.
        """
        if self.schema == None:
            self.create_schema()
        
        tfdv.write_schema_text(self.schema, f"../data/data_validation/{schema_title}.pbtxt")

        print(f"The data schema has been successfully saved in '../data/data_validation/{schema_title}.pbtxt'")

    def save_stats(self, stats_title: str) -> None:
        """
        Saves the dataset statistics to a file.

        Args:
            stats_title (str): Title for the statistics file.
        """
        if self.stats != None:
            tfdv.write_stats_text(self.stats, f"../data/data_validation/{stats_title}.txt")
        else:
            raise ValueError("There are no statistics, use 'create_stats()' to create.")
        
        print(f"The data stats has been successfully saved in '../data/data_validation/{stats_title}.txt'")
    
    def load_schema(self, schema_path: str) -> schema_pb2.Schema:
        """
        Loads the data schema from a file.

        Args:
            schema_path (str): Path to the schema file.

        Returns:
            schema_pb2.Schema: Loaded data schema.
        """
        self.schema: schema_pb2.Schema = tfdv.load_schema_text(schema_path)
        return self.schema

    def load_stats(self, stats_path: str) -> statistics_pb2.DatasetFeatureStatisticsList:
        """
        Loads the dataset statistics from a file.

        Args:
            stats_path (str): Path to the statistics file.

        Returns:
            statistics_pb2.DatasetFeatureStatisticsList: Loaded dataset statistics.
        """
        self.stats: statistics_pb2.DatasetFeatureStatisticsList = tfdv.load_stats_text(stats_path)
        return self.stats


    def validate_data(self, new_stats: statistics_pb2.DatasetFeatureStatisticsList, drift_feature_threshold_dict: dict=None, skew_feature_threshold_dict: dict=None) -> None:
        """
        Validates the new dataset statistics against the existing data statistics.

        Args:
            new_stats (statistics_pb2.DatasetFeatureStatisticsList): New dataset statistics to be validated.
            drift_feature_threshold_dict (dict, optional): Dictionary containing drift feature threshold values.
            skew_feature_threshold_dict (dict, optional): Dictionary containing skew feature threshold values.
        
        Returns:
            None
        
        Raises:
            ValueError: If there are no statistics or schema, use 'create_stats()' and 'create_schema()' to create.
        """
        if self.stats == None:
            raise ValueError("There are no statistics, use 'create_stats()' to create.")
        elif self.schema == None:
            self.create_schema()

        if drift_feature_threshold_dict is not None:
            for feature, threshold in drift_feature_threshold_dict.items():
                tfdv.get_feature(self.schema, feature).drift_comparator.infinity_norm.threshold = threshold
        
        if skew_feature_threshold_dict is not None:
            for feature, threshold in skew_feature_threshold_dict.items():
                tfdv.get_feature(self.schema, feature).skew_comparator.infinity_norm.threshold = threshold

        anomalies = tfdv.validate_statistics(statistics=new_stats, schema=self.schema, serving_statistics=self.stats, previous_statistics=self.stats)

        tfdv.display_anomalies(anomalies)

        tfdv.visualize_statistics(lhs_statistics=self.stats, rhs_statistics=new_stats, lhs_name="Serving Data Stats", rhs_name="New Data Stats")
        return anomalies
